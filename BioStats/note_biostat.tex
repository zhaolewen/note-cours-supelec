\documenttype{article}
\usepackage{amsfont}

\title{Bio-Statistique}
\maketitle

\begin{document}
\section{Methodologie du test statistique}

\begin{equation}
X_1,\ldots,\X_{n_1} ~\mathcal{N}(\mu_1,\sigma^2)
\end{equation}
\begin{equation}
Y_1,\ldots,Y_{n_2} ~\mathcal{N}(\mu_2,\sigma^2)
\end{equation}

Test d'hypoth\`ese
\begin{equation}
H_0 \{\mu_1=\mu_2\} vs H_1 \{\mu_1\neq\mu_2\}
\end{equation}

Pour rejeter (ou non) l'hypoth\`ese nulle, on utilise une statistique de test dont on connait la distribution sous $H_0$ (m\^eme asymptotiquement).
Ici, on utilisera le test de student de statistique associ\'ee
\begin{equation}
T=\frac{\bar{X}-\bar{Y}}{s\sqrt{\frac{1}{n_1}-\frac{1}{n_2}}}
\end{equation}
avec
\begin{equation}
s=\sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}
\end{equation}
Parce que la loi de $T$ est connue sous $H_0$, on peut controler l'erreur de 1er esp\`ece et on peut calculer des p-values.

\begin{center}
\begin{tabular}
(Realit\'e/D'ecision) & non rejet de $H_0$ & rejet de $H_0$\\
$H_0$ vraie & OK & erreur de 1er esp\`ece (faux positif)\\
$H_0$ faux & erreur de 2e esp\`ece (faux n\'egatif) & OK
\end{tabular}
\end{center}
Notons $\alpha=\mathbb{P}(rejet de H_0 | H_0 vraie)$ erreur de 1er esp\`ece.

\textbf{p-value}
Probabilit\'e sous $H_0$ d'avoir une value de $T$ plus grande que celle observ\'ee.

\begin{equation}
p=\mathbb{P}_{H_0}(|T|>|t_{obs}|)
\end{equation}

On comprend donc bien que plus $p$ est petit, plus on aura tendance \`a rejeter l'hypoth\`ese nulle. $=>$ Rejet de $H_0$ si $p<seuil$. La p-value est une normalisation particulier de la statistique de sorte que sous $H_0$, $p~\mathcal{U}[0,1]$
\begin{center}
\begin{tabular}
seuil & $\mathbb{P}_{H_0}(p<seuil)$ \\
1 & 1\\
0.5 & 0.5 \\
$\alpha$ & $\alpha$
\end{tabular}
\end{center}
Si on veut controler l'erreur de premi\`ere esp\`ece au seuil $\alpha$, rejet de $H_0$ si $p<=\alpha$

La probl\`ematique des tests multiples
Pour un test:
\begin{center}
\begin{tabular}
(R\'ealit\'e/D\'ecision) & $H_0$ non rejet\'ee & $H_0$ rejet\'ee\\
$H_0$ vraie & TN & FP\\
$H_0$ faux & FN & TP
\end{tabular}
\end{center}

Pour une famille de $m$ tests
\begin{center}
\begin{tabular}
(R\'ealit\'e/D\'ecision) & $H_0$ non rejet\'ee & $H_0$ rejet\'ee & \\
$H_0$ vraie & $U$ & $V$ & m_0 \\
$H_0$ fausse & $T$ & $S$ & m_1 \\
& $W$ & $S$ & $m$
\end{tabular}
\end{center}
$m_0$ nombre de variables (ex. g\`enes) v\'erifiant l'hypoth\'ese nulle.
$m_1$ nombre de variables v\'erifiant l'alternative.
$m_0,m_1$ inconnue.

$m$ nombre de g\`ene test\'es.
$R$ nombre d'hypoth\`ese nulle rejet\'ee.

On suppose que $m_0$ hypoth\`ese $H_0$ vraies.
On suppose que tous les tests sont men\'es au niveau $\alpha$.
\begin{equation}
\left\{\begin{array}[rcl]
E_1=1 & si p_1<\alpha\\
E_1=0 & sinon
\end{array}\right.
=> E_1 ~ \mathcal{B}(\alpha)
\end{equation}

\begin{equation}
\left\{\begin{array}[rcl]
E_2=1 & si p_2<\alpha\\
E_2=0 & sinon
\end{array}\right.
=> E_2 ~ \mathcal{B}(\alpha)
\end{equation}

...

\begin{equation}
\left\{\begin{array}[rcl]
E_{m_0}=1 & si p_{m_0}<\alpha\\
E_{m_0}=0 & sinon
\end{array}\right.
=> E_{m_0} ~ \mathcal{B}(\alpha)
\end{equation}
\begin{equation}
=>\V=-\sum_{k=1}^{m_0} E_k ~ \mathcal{B}_{in}(m_0,\alpha)
\end{equation}

On a $\mathbb{E}[V]=m_0\alpha$
Conclusion: le nombre attendu de faux positifs augmente lin\'eairement avec $m_0$. 

Dans ce contexte, on s'int\'eresse au FWER (Family Wise Error Rate) d\'efini par:
\begin{equation}
FWER = \mathbb{P}(V>0)
\end{equation}
= Probabilit\'e de rejeter au moins une fois l'hypoth\`ese nulle \`a tort dans la famille des tests r\'ealis\'es.

Procedure de contr\^ole du FWER: Bonferroni.

La correction de Bonferroni.

Soient une famille de $m$ tests et leur p-value individuelle $p_1,\ldots,p_m$.
Soit $I_0$ un vecteur de valeur indexant les vraies hypoth\`ese nulles
\begin{equation}
card(I_0)=m_0
\end{equation}
\begin{equation}
FWER = \mathbb{P}(V>0)=\mathbb{P}(U_I_0 \{p_i<\alpha\}) <=_{in\'egalit\'e Boole} \sum_{I_0} P(p_i<\alpha)=m_0\alpha
\end{equation}
Si on veut garantir un contr\^ole du FWER et ce quelque soit le "motif" d'hypoth\'ese nulles et alternatives, on pose 
\begin{equation}
\alpha <- \frac{\alpha}{m}
\end{equation}

Conclusion
On rejette $H_{0_\alpha}_{1<=\alpha<=m}$ si $p_\alpha<=\frac{\alpha}{m}$
$<=>$ On rejette $H_{0_\alpha}$ si 
\begin{equation}
p_\alpha^{adj}=mp_alpha<=\alpha
\end{equation}

Proc\'edure de contr\^ole de FWER: Correction de Sidak
\begin{equation}
\begin{split}
FWER&=\mathcal{P}(V>0)=\mathcal{P}(\{p_1<\alpha\}U\ldots\{p_m<\alpha\})\\
&=1-\mathbb{P}(\{p_1>\alpha\} n\ldots n \{p_m>\alpha\})\\
&=_{independance des tests r\'ealis\'es} 1-\Pi_{i=1}^{m}\mathbb{P}(p_i>\alpha)\\
&=1-(1-\alpha)^m<\alpha^*=0.05
\end{split}
\end{equation}

On a donc 
\begin{equation}
\alpha=1-(1-\alpha^*)^{\frac{1}{m}}
\end{equation}

Conclusion

On rejette $H_0$ si $p_\alpha <= 1-(1-\alpha^*)^{\frac{1}{m}}$
$<=>$ on rejette $H_{0_\alpha}$ si $p_\alpha^{adj}=1-(1-p_\alpha)^m<\alpha$

Exercise
Mener une connection Sidak sur les donn\'ees simul\'ees de la s\'eance pr\'ec\'edente

* Comparer les $p_{adj}^{Bonf}/$ et $p_{adj}^{Sidak}$

\subsection{Le False Discovery Rate (FDR)}

Une approche qui a radicalement r\'evolutionn\'e la probl\`ematique des tests multiples est le FDR(Benjamini & Hachberg 1993). Plut\^ot que de contr\^oler le FWER, le FDR cherche \`a contr\^oler la proportion d'erreurs. (approach beaucoup moins conservative):
\begin{equation}
FDR=\mathbb{E}[\frac{V}{R}]
\end{equation}

L'objectif est bien \'evidemment de contr\^oler la valeur du FDR \`a une valeur pr\'efix\'ee $\alpha(=0.05)$

Au niveau $\alpha$, le nombre d'hypoth\'esenulle rejet\'ees est not\'e $m(\alpha)$
Le nombre de faux positifs attendus $\mathbb{E}[V]=m_0\alpha$. Une estimation du FDR est donn\'ee par
\begin{equation}
\hat{FDR}(\alpha)=\frac{m_0\alpha}{m(\alpha)}
\end{equation}

De cette estimation du FDR, BH propose la proc\'edure s\'equentielle suivante:

\textbf{Etape 1}: Soient $p_1,\ldots,p_m$ les p-values individuelles et $p_{1}<=p_{2}<=\ldots<=p_{m}$ avec $p_{(k)}$ la $k$\`eme plus petite p-value. 

Au seuil $\alpha=p_{(k)}$, le ombre d'hypoth\`ese nulle rejet\'es est egal \`a $k$.

* Nombre de fausse positives attendues
\begin{equation}
\mathbb{E}[V]=m_0p_{(k)}<=mp_{(k)}
\end{equation} 
Donc 
\begin{equation}
\hat{FDR}(p_{(k)})=\frac{mp_{(k)}}{k}
\end{equation}
On cherche alors la valeur maximale de $k$ telle que $p_{(k)}$ v\'erifie
\begin{equation}
\frac{mp_{(k)}}{k}<=\alpha^*
\end{equation}
En d'autres termes
\begin{equation}
k=argmax_i (p_{(i)}<=\frac{i}{m}\alpha^*)
\end{equation}
on rejette alors les $k$ premi\`eres hypoth\`eses.

En terme de p-value ajust\'ees
\begin{equation}
p_{adj}^{BH}=p_{m}
\end{equation}
\begin{equation}
p_{adj}^{BH}(\alpha)=min(p_{\alpha+1}^{adj},\frac{mp(\alpha)}{\alpha})
\end{equation}

Petit exemple illustratif:

\begin{equation}
p_1=0.06,p_2=0.02,p_3=0.03
\end{equation}

Par Bonferioni,
\begin{equation}
p_1^{Bonf}=0.18,p_2^{Bonf}=0.06, p_3^{Bonf}=0.09
\end{equation}
On compare ces p-values ajust\'ees \`a $\alpha=0.05$
$=>$ Aucune hypoth\`ese rejet\'ees !!!

Par Benjamini & Hachberg
\begin{equation}
p_{(1)}=p_2=0.02, p_{(2)}=p_3=0.03,p_{(3)}=p_1=0.06
\end{equation}

\begin{equation}
p_{(3)}<=0.05 => Non
\end{equation}
\begin{equation}
p_{(2)}<=\frac{(m-1)\times 0.05}{m}=0.033333 => Oui 
\end{equation}
$H_{(3)}$ non rejet\'ee, $H_{(1)}$ et $H_{(2)}$ rejet\'ee

En terme de p-value ajust\'ee
\begin{equation}
p_{(3)}^{BH}=p_{(3)}=0.06
\end{equation}
\begin{equation}
p_{(2)}^{BH}=min(p_{(3)}^{BH},\frac{3}{2}p_{(2)})=0.045
\end{equation}
\begin{equation}
p_{(1)}^{BH}
\end{equation}

\end{document}